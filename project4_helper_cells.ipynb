{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d10885d2",
   "metadata": {},
   "source": [
    "## ğŸ“Š How to Monitor Training Progress\n",
    "\n",
    "Detectron2 provides multiple ways to track training:\n",
    "\n",
    "### **Method 1: TensorBoard (Real-time Visualization)**\n",
    "Open a terminal and run:\n",
    "```bash\n",
    "tensorboard --logdir=./outputs\n",
    "```\n",
    "Then open http://localhost:6006 in your browser to see live loss curves, learning rate, etc.\n",
    "\n",
    "### **Method 2: Jupyter Output (Console Logs)**\n",
    "Detectron2 automatically prints training status. You'll see messages like:\n",
    "```\n",
    "[01/13 10:23:45] d2.engine.train_loop WARNING: ...\n",
    "[01/13 10:23:50] d2.engine.train_loop INFO: [Iteration 50/1000] ...\n",
    "````\n",
    "\n",
    "### **Method 3: Check Training Files**\n",
    "Training checkpoints are saved to `./outputs/` automatically. Check file modification times:\n",
    "```bash\n",
    "ls -lh ./outputs/model_*.pth  # See if new checkpoints appear\n",
    "```\n",
    "\n",
    "### **If Training Seems \"Hung\":**\n",
    "1. Check if the GPU is being used: `nvidia-smi` (in terminal)\n",
    "2. Look for the log file: `./outputs/log.txt`\n",
    "3. Check if a checkpoint file is being created (means training is working!)\n",
    "4. Wait at least 1-2 minutes before concluding it's hung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773ae694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de82404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Reference: What You'll See During Training\n",
    "\n",
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                   TRAINING PROGRESS INDICATORS                             â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "When you run trainer.train(), Detectron2 will output messages like:\n",
    "\n",
    "ğŸ“‹ LOG EXAMPLE:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "[01/13 10:23:45] d2.engine.train_loop WARNING: Using 0 GPUs\n",
    "[01/13 10:24:15] d2.engine.train_loop INFO: [Iteration 50/1000] total_loss: 2.345\n",
    "[01/13 10:24:45] d2.engine.train_loop INFO: [Iteration 100/1000] total_loss: 1.987\n",
    "[01/13 10:25:15] d2.engine.train_loop INFO: [Iteration 150/1000] total_loss: 1.654\n",
    "...\n",
    "\n",
    "ğŸ” WHAT EACH PART MEANS:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "â€¢ [01/13 10:24:15]     = Date/time stamp\n",
    "â€¢ d2.engine.train_loop = Detectron2 module name\n",
    "â€¢ Iteration 50/1000    = Current iteration out of max\n",
    "â€¢ total_loss: 2.345    = Current training loss (should decrease over time!)\n",
    "\n",
    "ğŸ“Š LOSS TRENDS:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "âœ… GOOD:   2.5 â†’ 2.0 â†’ 1.5 â†’ 1.0  (loss decreasing = training working!)\n",
    "âŒ BAD:    2.5 â†’ 2.4 â†’ 2.5 â†’ 2.6   (loss not changing = check config)\n",
    "âŒ BAD:    NaN or Inf              (data/model issue = check inputs)\n",
    "\n",
    "â±ï¸ TIMING:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "â€¢ First few iterations are slower (GPU warmup, data load)\n",
    "â€¢ After warmup, speed stabilizes to ~1-10 iterations/sec (depending on GPU)\n",
    "â€¢ For 1000 iterations at 2 iter/sec = ~8 minutes\n",
    "\n",
    "ğŸ¯ QUICK CHECKS TO CONFIRM TRAINING IS NOT HUNG:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "1ï¸âƒ£ CHECK GPU USAGE:\n",
    "   Terminal: nvidia-smi\n",
    "   Look for: python process using memory\n",
    "\n",
    "2ï¸âƒ£ CHECK FILES CREATED:\n",
    "   Terminal: ls -lh ./outputs/\n",
    "   Look for: model_*.pth files with recent timestamps\n",
    "\n",
    "3ï¸âƒ£ CHECK LOG FILE:\n",
    "   Terminal: tail -f ./outputs/log.txt\n",
    "   Look for: Recent timestamps and loss values\n",
    "\n",
    "4ï¸âƒ£ LOOK AT TERMINAL OUTPUT:\n",
    "   The notebook should print \"Iteration X/Y\" messages regularly\n",
    "\n",
    "\n",
    "ğŸ›‘ COMMON ISSUES:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "Issue: No output for 5+ minutes\n",
    "Solution:\n",
    "  â€¢ First minibatch might load slowly (~1-2 min on first run)\n",
    "  â€¢ Check GPU usage with nvidia-smi\n",
    "  â€¢ Check if process is running (ps aux | grep python)\n",
    "\n",
    "Issue: \"CUDA out of memory\"\n",
    "Solution:\n",
    "  â€¢ Reduce cfg.SOLVER.IMS_PER_BATCH (currently = 4)\n",
    "  â€¢ Reduce image size (currently = 512x512)\n",
    "\n",
    "Issue: Loss is NaN\n",
    "Solution:\n",
    "  â€¢ Check data pipeline (run test cells 25-26 first!)\n",
    "  â€¢ Reduce learning rate\n",
    "  â€¢ Check for corrupted images\n",
    "\n",
    "Issue: Loss not decreasing\n",
    "Solution:\n",
    "  â€¢ Training is still warming up (first 50-100 iterations)\n",
    "  â€¢ Learning rate might be too high/low\n",
    "  â€¢ Dataset might be too small\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Next: Run the training cell above! You should see output like the LOG EXAMPLE.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nâœ… Press the cells above to start training.\")\n",
    "print(\"   You'll see real-time progress in the output!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a352ad1",
   "metadata": {},
   "source": [
    "### ğŸ” Test Wrapper: Understanding `build_train_loader` Step-by-Step\n",
    "\n",
    "This cell allows you to **inspect the data transformation** without running full training.\n",
    "\n",
    "**What it does:**\n",
    "- Takes a small batch from your dataset\n",
    "- Shows the transformation at each step\n",
    "- Prints shapes, types, and values\n",
    "- Visualizes the final Detectron2 format\n",
    "\n",
    "**Run this cell independently** to understand the data pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cdd442",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ğŸ§ª TEST WRAPPER: Step-by-Step Data Transformation Inspector\n",
    "============================================================\n",
    "\n",
    "This test wrapper helps you understand what happens inside build_train_loader\n",
    "without running full training. Run this cell to see the data flow!\n",
    "\"\"\"\n",
    "\n",
    "from detectron2.structures import Instances, Boxes, BitMasks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def test_collate_function():\n",
    "    \"\"\"\n",
    "    Test wrapper to inspect the collate_fn_batches transformation\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"ğŸ” DATA TRANSFORMATION TEST - STEP BY STEP\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # =====================================================\n",
    "    # STEP 1: Get a small batch from train_dataset\n",
    "    # =====================================================\n",
    "    print(\"\\nğŸ“¦ STEP 1: Loading raw batch from train_dataset\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    batch_size = 2  # Small batch for inspection\n",
    "    batch = [train_dataset[i] for i in range(batch_size)]\n",
    "\n",
    "    print(f\"âœ“ Loaded {len(batch)} samples\")\n",
    "    print(f\"  Each sample is a tuple: (image_tensor, mask_tensor)\")\n",
    "    print(f\"\\n  Sample 0 structure:\")\n",
    "    print(f\"    - image type: {type(batch[0][0])}\")\n",
    "    print(f\"    - image shape: {batch[0][0].shape if hasattr(batch[0][0], 'shape') else 'N/A'}\")\n",
    "    print(f\"    - mask type: {type(batch[0][1])}\")\n",
    "    print(f\"    - mask shape: {batch[0][1].shape if hasattr(batch[0][1], 'shape') else 'N/A'}\")\n",
    "\n",
    "    # =====================================================\n",
    "    # STEP 2: Convert tensors to numpy\n",
    "    # =====================================================\n",
    "    print(\"\\n\\nğŸ”„ STEP 2: Converting tensors to numpy arrays\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    image, mask = batch[0]  # Take first sample\n",
    "\n",
    "    print(f\"Before conversion:\")\n",
    "    print(f\"  image: {type(image)}, shape={image.shape if hasattr(image, 'shape') else 'N/A'}\")\n",
    "    print(f\"  mask: {type(mask)}, shape={mask.shape if hasattr(mask, 'shape') else 'N/A'}\")\n",
    "\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image = image.cpu().numpy()\n",
    "    if isinstance(mask, torch.Tensor):\n",
    "        mask = mask.cpu().numpy()\n",
    "\n",
    "    print(f\"\\nAfter conversion:\")\n",
    "    print(f\"  image: {type(image)}, shape={image.shape}, dtype={image.dtype}\")\n",
    "    print(f\"  mask: {type(mask)}, shape={mask.shape}, dtype={mask.dtype}\")\n",
    "\n",
    "    # =====================================================\n",
    "    # STEP 3: Transpose image [C, H, W] â†’ [H, W, C]\n",
    "    # =====================================================\n",
    "    print(\"\\n\\nğŸ“ STEP 3: Transposing image for Detectron2 format\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    print(f\"Before transpose: {image.shape} (channels first)\")\n",
    "\n",
    "    if image.ndim == 3 and image.shape[0] in [1, 3]:\n",
    "        image = np.transpose(image, (1, 2, 0))\n",
    "\n",
    "    print(f\"After transpose: {image.shape} (channels last)\")\n",
    "    print(f\"  This is the format Detectron2 expects: [Height, Width, Channels]\")\n",
    "\n",
    "    # =====================================================\n",
    "    # STEP 4: Convert to uint8 (0-255 range)\n",
    "    # =====================================================\n",
    "    print(\"\\n\\nğŸ¨ STEP 4: Converting to uint8 format (0-255)\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    print(f\"Before conversion:\")\n",
    "    print(f\"  dtype: {image.dtype}, min={image.min():.4f}, max={image.max():.4f}\")\n",
    "\n",
    "    if image.max() <= 1.0:\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "        print(f\"\\nAfter conversion (was normalized 0-1):\")\n",
    "    else:\n",
    "        image = image.astype(np.uint8)\n",
    "        print(f\"\\nAfter conversion (was already 0-255):\")\n",
    "\n",
    "    print(f\"  dtype: {image.dtype}, min={image.min()}, max={image.max()}\")\n",
    "\n",
    "    # =====================================================\n",
    "    # STEP 5: Convert semantic mask to instance format\n",
    "    # =====================================================\n",
    "    print(\"\\n\\nğŸ­ STEP 5: Converting semantic segmentation to instance format\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    h, w = mask.shape\n",
    "    print(f\"Mask shape: {mask.shape} (H={h}, W={w})\")\n",
    "    print(f\"Unique classes in mask: {np.unique(mask)}\")\n",
    "\n",
    "    instances = Instances((h, w))\n",
    "    print(f\"âœ“ Created empty Instances object with image_size=({h}, {w})\")\n",
    "\n",
    "    # Find unique classes (excluding background)\n",
    "    sem_seg = torch.from_numpy(mask.astype(np.int32))\n",
    "    unique_classes = torch.unique(sem_seg)\n",
    "    unique_classes = unique_classes[unique_classes > 0]  # Skip background (class 0)\n",
    "\n",
    "    print(f\"\\nClasses to process (excluding background): {unique_classes.tolist()}\")\n",
    "\n",
    "    # =====================================================\n",
    "    # STEP 6: Extract masks and bounding boxes per class\n",
    "    # =====================================================\n",
    "    print(\"\\n\\nğŸ“¦ STEP 6: Extracting per-class masks and bounding boxes\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    class_masks = []\n",
    "    class_labels = []\n",
    "    boxes_list = []\n",
    "\n",
    "    for idx, class_id in enumerate(unique_classes):\n",
    "        print(f\"\\nProcessing class {int(class_id)}:\")\n",
    "\n",
    "        # Create binary mask for this class\n",
    "        class_mask = (sem_seg == class_id).numpy().astype(np.uint8)\n",
    "        print(f\"  Binary mask: {class_mask.shape}, pixels={class_mask.sum()}\")\n",
    "\n",
    "        # Find bounding box\n",
    "        rows = np.any(class_mask, axis=1)\n",
    "        cols = np.any(class_mask, axis=0)\n",
    "\n",
    "        if rows.any() and cols.any():\n",
    "            y_min, y_max = np.where(rows)[0][[0, -1]]\n",
    "            x_min, x_max = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "            if x_max > x_min and y_max > y_min:\n",
    "                box = [float(x_min), float(y_min), float(x_max + 1), float(y_max + 1)]\n",
    "                print(f\"  Bounding box: x=[{x_min}, {x_max}], y=[{y_min}, {y_max}]\")\n",
    "                print(f\"  Box area: {(x_max - x_min) * (y_max - y_min)} pixels\")\n",
    "\n",
    "                class_masks.append(torch.from_numpy(class_mask.astype(np.float32)))\n",
    "                class_labels.append(int(class_id))\n",
    "                boxes_list.append(box)\n",
    "\n",
    "    print(f\"\\nâœ“ Extracted {len(class_masks)} valid instances\")\n",
    "\n",
    "    # =====================================================\n",
    "    # STEP 7: Wrapping in Detectron2 structures\n",
    "    # =====================================================\n",
    "    print(\"\\n\\nğŸ STEP 7: Wrapping in Detectron2 structures\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    if class_masks:\n",
    "        print(f\"Creating structures for {len(class_masks)} instances:\")\n",
    "\n",
    "        # Stack masks and wrap in BitMasks\n",
    "        masks_tensor = torch.stack(class_masks)\n",
    "        print(f\"  1. Masks tensor shape: {masks_tensor.shape} (N, H, W)\")\n",
    "\n",
    "        instances.gt_masks = BitMasks(masks_tensor)\n",
    "        print(f\"  2. âœ“ Wrapped in BitMasks: {type(instances.gt_masks)}\")\n",
    "        print(f\"     - Has crop_and_resize: {hasattr(instances.gt_masks, 'crop_and_resize')}\")\n",
    "\n",
    "        instances.gt_classes = torch.tensor(class_labels, dtype=torch.int64)\n",
    "        print(f\"  3. âœ“ Classes: {instances.gt_classes.tolist()}\")\n",
    "\n",
    "        instances.gt_boxes = Boxes(torch.tensor(boxes_list, dtype=torch.float32))\n",
    "        print(f\"  4. âœ“ Boxes shape: {instances.gt_boxes.tensor.shape}\")\n",
    "    else:\n",
    "        print(\"No instances found - creating empty structures\")\n",
    "        instances.gt_masks = BitMasks(torch.zeros((0, h, w), dtype=torch.float32))\n",
    "        instances.gt_classes = torch.zeros(0, dtype=torch.int64)\n",
    "        instances.gt_boxes = Boxes(torch.zeros((0, 4), dtype=torch.float32))\n",
    "\n",
    "    # =====================================================\n",
    "    # STEP 8: Final Detectron2 format\n",
    "    # =====================================================\n",
    "    print(\"\\n\\nâœ… STEP 8: Final Detectron2 format\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Prepare image tensor\n",
    "    image_tensor = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "    sample_dict = {\n",
    "        \"image\": image_tensor,\n",
    "        \"instances\": instances\n",
    "    }\n",
    "\n",
    "    print(f\"Final dictionary structure:\")\n",
    "    print(f\"  'image':\")\n",
    "    print(f\"    - type: {type(sample_dict['image'])}\")\n",
    "    print(f\"    - shape: {sample_dict['image'].shape}\")\n",
    "    print(f\"    - dtype: {sample_dict['image'].dtype}\")\n",
    "    print(f\"    - range: [{sample_dict['image'].min():.4f}, {sample_dict['image'].max():.4f}]\")\n",
    "\n",
    "    print(f\"\\n  'instances':\")\n",
    "    print(f\"    - type: {type(sample_dict['instances'])}\")\n",
    "    print(f\"    - image_size: {sample_dict['instances'].image_size}\")\n",
    "    print(f\"    - has gt_masks: {sample_dict['instances'].has('gt_masks')}\")\n",
    "    print(f\"    - has gt_classes: {sample_dict['instances'].has('gt_classes')}\")\n",
    "    print(f\"    - has gt_boxes: {sample_dict['instances'].has('gt_boxes')}\")\n",
    "\n",
    "    if sample_dict['instances'].has('gt_masks'):\n",
    "        print(f\"    - num_instances: {len(sample_dict['instances'])}\")\n",
    "        print(f\"    - gt_masks type: {type(sample_dict['instances'].gt_masks)}\")\n",
    "        print(f\"    - gt_classes: {sample_dict['instances'].gt_classes.tolist()}\")\n",
    "\n",
    "    # =====================================================\n",
    "    # STEP 9: Visualization\n",
    "    # =====================================================\n",
    "    print(\"\\n\\nğŸ¨ STEP 9: Visualization\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Original image\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title(\"Original Image\\n(uint8, [H, W, C])\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Semantic mask\n",
    "    axes[1].imshow(mask, cmap='tab20', vmin=0, vmax=12)\n",
    "    axes[1].set_title(f\"Semantic Mask\\n{len(unique_classes)} classes\")\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # Bounding boxes overlay\n",
    "    axes[2].imshow(image)\n",
    "    if instances.has('gt_boxes'):\n",
    "        for box, label in zip(instances.gt_boxes.tensor, instances.gt_classes):\n",
    "            x1, y1, x2, y2 = box.tolist()\n",
    "            rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                                fill=False, edgecolor='red', linewidth=2)\n",
    "            axes[2].add_patch(rect)\n",
    "            axes[2].text(x1, y1-5, f'Class {int(label)}',\n",
    "                        color='red', fontsize=10, weight='bold',\n",
    "                        bbox=dict(facecolor='white', alpha=0.7))\n",
    "    axes[2].set_title(f\"Instance Boxes\\n{len(instances)} instances\")\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"âœ… TEST COMPLETE!\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nKey Takeaways:\")\n",
    "    print(\"  1. Raw data: PyTorch tensors [C, H, W], normalized 0-1\")\n",
    "    print(\"  2. Detectron2 needs: numpy [H, W, C], uint8 0-255\")\n",
    "    print(\"  3. Semantic masks â†’ Instance format (per-class masks + boxes)\")\n",
    "    print(\"  4. BitMasks wrapper enables Detectron2's internal operations\")\n",
    "    print(\"  5. Final format: dict with 'image' tensor and 'instances' object\")\n",
    "\n",
    "    return sample_dict\n",
    "\n",
    "# Run the test\n",
    "print(\"ğŸš€ Running data transformation test...\\n\")\n",
    "test_sample = test_collate_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0bb04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ğŸ§ª BONUS: Test the actual collate_fn_batches function\n",
    "======================================================\n",
    "\n",
    "This tests the EXACT function used in build_train_loader with a batch.\n",
    "\"\"\"\n",
    "\n",
    "def test_actual_collate_function():\n",
    "    \"\"\"\n",
    "    Test the actual collate function that will be used during training\n",
    "    \"\"\"\n",
    "    from detectron2.structures import Instances, Boxes, BitMasks\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(\"ğŸ”¬ TESTING ACTUAL COLLATE FUNCTION (with batch)\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # This is the EXACT collate function from build_train_loader\n",
    "    def collate_fn_batches(batch):\n",
    "        \"\"\"The actual collate function used in DataLoader\"\"\"\n",
    "        batch_data = []\n",
    "        for image, mask in batch:\n",
    "            # Convert tensor to numpy if needed\n",
    "            if isinstance(image, torch.Tensor):\n",
    "                image = image.cpu().numpy()\n",
    "            if isinstance(mask, torch.Tensor):\n",
    "                mask = mask.cpu().numpy()\n",
    "\n",
    "            # Convert [C, H, W] image to [H, W, C] for Detectron2\n",
    "            if image.ndim == 3 and image.shape[0] in [1, 3]:\n",
    "                image = np.transpose(image, (1, 2, 0))\n",
    "\n",
    "            # Ensure uint8 format (0-255)\n",
    "            if image.max() <= 1.0:\n",
    "                image = (image * 255).astype(np.uint8)\n",
    "            else:\n",
    "                image = image.astype(np.uint8)\n",
    "\n",
    "            # Convert semantic segmentation to instance annotations\n",
    "            h, w = mask.shape\n",
    "            instances = Instances((h, w))\n",
    "\n",
    "            sem_seg = torch.from_numpy(mask.astype(np.int32))\n",
    "            unique_classes = torch.unique(sem_seg)\n",
    "            unique_classes = unique_classes[unique_classes > 0]\n",
    "\n",
    "            class_masks = []\n",
    "            class_labels = []\n",
    "            boxes_list = []\n",
    "\n",
    "            if len(unique_classes) > 0:\n",
    "                for class_id in unique_classes:\n",
    "                    class_mask = (sem_seg == class_id).numpy().astype(np.uint8)\n",
    "                    rows = np.any(class_mask, axis=1)\n",
    "                    cols = np.any(class_mask, axis=0)\n",
    "\n",
    "                    if rows.any() and cols.any():\n",
    "                        y_min, y_max = np.where(rows)[0][[0, -1]]\n",
    "                        x_min, x_max = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "                        if x_max > x_min and y_max > y_min:\n",
    "                            class_masks.append(torch.from_numpy(class_mask.astype(np.float32)))\n",
    "                            class_labels.append(int(class_id))\n",
    "                            boxes_list.append([float(x_min), float(y_min), float(x_max + 1), float(y_max + 1)])\n",
    "\n",
    "            # Set instances (with BitMasks wrapper)\n",
    "            if class_masks:\n",
    "                instances.gt_masks = BitMasks(torch.stack(class_masks))\n",
    "                instances.gt_classes = torch.tensor(class_labels, dtype=torch.int64)\n",
    "                instances.gt_boxes = Boxes(torch.tensor(boxes_list, dtype=torch.float32))\n",
    "            else:\n",
    "                instances.gt_masks = BitMasks(torch.zeros((0, h, w), dtype=torch.float32))\n",
    "                instances.gt_classes = torch.zeros(0, dtype=torch.int64)\n",
    "                instances.gt_boxes = Boxes(torch.zeros((0, 4), dtype=torch.float32))\n",
    "\n",
    "            batch_data.append({\n",
    "                \"image\": torch.from_numpy(image).permute(2, 0, 1).float() / 255.0,\n",
    "                \"instances\": instances\n",
    "            })\n",
    "\n",
    "        return batch_data\n",
    "\n",
    "    # Test with a small batch\n",
    "    print(\"\\nğŸ“¦ Creating test batch (3 samples)...\")\n",
    "    batch = [train_dataset[i] for i in range(3)]\n",
    "    print(f\"âœ“ Batch created: {len(batch)} samples\")\n",
    "\n",
    "    print(\"\\nğŸ”„ Running collate_fn_batches...\")\n",
    "    try:\n",
    "        collated_batch = collate_fn_batches(batch)\n",
    "        print(f\"âœ… Success! Collated batch has {len(collated_batch)} samples\")\n",
    "\n",
    "        print(\"\\nğŸ“Š Batch Statistics:\")\n",
    "        for idx, sample in enumerate(collated_batch):\n",
    "            print(f\"\\n  Sample {idx}:\")\n",
    "            print(f\"    - Image shape: {sample['image'].shape}\")\n",
    "            print(f\"    - Image dtype: {sample['image'].dtype}\")\n",
    "            print(f\"    - Num instances: {len(sample['instances'])}\")\n",
    "            if len(sample['instances']) > 0:\n",
    "                print(f\"    - Classes: {sample['instances'].gt_classes.tolist()}\")\n",
    "                print(f\"    - Masks type: {type(sample['instances'].gt_masks)}\")\n",
    "                print(f\"    - Has crop_and_resize: {hasattr(sample['instances'].gt_masks, 'crop_and_resize')}\")\n",
    "\n",
    "        print(\"\\nâœ… All samples successfully converted to Detectron2 format!\")\n",
    "        print(\"\\nğŸ’¡ This is exactly what gets fed to the model during training.\")\n",
    "\n",
    "        return collated_batch\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Run the test\n",
    "print(\"\\nğŸš€ Running actual collate function test...\\n\")\n",
    "collated_data = test_actual_collate_function()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“ LEARNING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "Why override build_train_loader?\n",
    "---------------------------------\n",
    "1. DEFAULT BEHAVIOR: Detectron2 loads images from file paths\n",
    "   - Applies its own augmentations\n",
    "   - May cause inconsistent preprocessing\n",
    "\n",
    "2. OUR OVERRIDE: Uses pre-processed data from cell 8\n",
    "   - Reuses your custom transforms (train_dataset)\n",
    "   - Consistent 512Ã—512 images\n",
    "   - Avoids shape mismatches\n",
    "\n",
    "What does collate_fn_batches do?\n",
    "---------------------------------\n",
    "Step 1: Convert PyTorch tensors â†’ NumPy arrays\n",
    "Step 2: Transpose [C,H,W] â†’ [H,W,C] (Detectron2 format)\n",
    "Step 3: Normalize to uint8 [0-255]\n",
    "Step 4: Semantic mask â†’ Instance format (per-class masks + boxes)\n",
    "Step 5: Wrap masks in BitMasks (enables crop_and_resize, etc.)\n",
    "Step 6: Return dict with 'image' and 'instances'\n",
    "\n",
    "Why BitMasks?\n",
    "-------------\n",
    "- Raw tensors don't have crop_and_resize() method\n",
    "- BitMasks is a Detectron2 structure with:\n",
    "  * crop_and_resize() - for augmentation\n",
    "  * to(device) - for GPU transfer\n",
    "  * cat() - for concatenation\n",
    "- Without BitMasks â†’ AttributeError during training\n",
    "\n",
    "Testing vs Breakpoints?\n",
    "------------------------\n",
    "âœ… Use test wrapper (this cell):\n",
    "   - Inspect data flow without interrupting training\n",
    "   - Run independently anytime\n",
    "   - See intermediate values clearly\n",
    "\n",
    "âŒ Don't use breakpoints during training:\n",
    "   - Function called 1000s of times per epoch\n",
    "   - Slows training significantly\n",
    "   - Hard to inspect specific samples\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee722344",
   "metadata": {},
   "source": [
    "### ğŸ“Š Comparison: `test_collate_function` vs `test_actual_collate_function`\n",
    "\n",
    "Here's the **key difference** between the two test wrappers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9dd2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ğŸ“‹ DETAILED COMPARISON TABLE\n",
    "============================\n",
    "\"\"\"\n",
    "\n",
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘             test_collate_function    vs    test_actual_collate_function    â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘                                                                            â•‘\n",
    "â•‘  PURPOSE:                                                                  â•‘\n",
    "â•‘  --------                                                                  â•‘\n",
    "â•‘  âœ“ DEEP LEARNING                âœ“ END-TO-END TESTING                      â•‘\n",
    "â•‘    (Educational breakdown)         (Practical validation)                  â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘  WHAT IT DOES:                                                             â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                             â•‘\n",
    "â•‘  â€¢ Tests ONE sample                 â€¢ Tests BATCH of 3 samples             â•‘\n",
    "â•‘  â€¢ Shows every transformation       â€¢ Shows batch-level processing        â•‘\n",
    "â•‘  â€¢ 9 detailed steps with prints    â€¢ 1 complete run (condensed prints)    â•‘\n",
    "â•‘  â€¢ Visualizes intermediate values  â€¢ Shows final batch statistics         â•‘\n",
    "â•‘  â€¢ Creates matplotlib plot          â€¢ Batch-level inspection              â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘  PRINT OUTPUT:                                                             â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                             â•‘\n",
    "â•‘  âœ“ Step-by-step annotations        âœ“ Faster, condensed output            â•‘\n",
    "â•‘  âœ“ Shape at every stage             âœ“ Summary statistics per sample       â•‘\n",
    "â•‘  âœ“ Data range (min/max)             âœ“ Batch-level info                   â•‘\n",
    "â•‘  âœ“ Class counts                     âœ“ Error handling included             â•‘\n",
    "â•‘  âœ“ Very detailed explanations (!)  âœ“ Learning summary at end             â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘  VISUALIZATION:                                                            â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                            â•‘\n",
    "â•‘  ğŸ“Š DETAILED (3 subplots):          ğŸ“Š NONE (batch operations only)        â•‘\n",
    "â•‘     â€¢ Original image                   (No plotting)                       â•‘\n",
    "â•‘     â€¢ Semantic mask                                                        â•‘\n",
    "â•‘     â€¢ Bounding boxes overlay                                               â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘  WHEN TO USE:                                                              â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                               â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘  ğŸ“ Use test_collate_function FIRST:                                       â•‘\n",
    "â•‘     â€¢ Learning the data pipeline                                           â•‘\n",
    "â•‘     â€¢ Understanding each transformation step                               â•‘\n",
    "â•‘     â€¢ Debugging shape mismatches                                           â•‘\n",
    "â•‘     â€¢ Verifying individual sample processing                               â•‘\n",
    "â•‘     â€¢ Getting visual insights with plots                                   â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘  âœ… Use test_actual_collate_function SECOND:                               â•‘\n",
    "â•‘     â€¢ Verifying the real collate function works                            â•‘\n",
    "â•‘     â€¢ Testing with actual batch size (like training)                       â•‘\n",
    "â•‘     â€¢ Checking batch-level behavior                                        â•‘\n",
    "â•‘     â€¢ Final validation before training                                     â•‘\n",
    "â•‘     â€¢ Quick sanity checks                                                  â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘  COMPARISON BY FEATURE:                                                    â•‘\n",
    "â•‘  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                    â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘  Pandas-style feature table:                                               â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘   Feature              â”‚  test_collate_function  â”‚  test_actual_collate   â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â•‘\n",
    "â•‘   Sample size          â”‚  1 sample               â”‚  3 samples (batch)     â•‘\n",
    "â•‘   Lines of code        â”‚  ~280 lines             â”‚  ~160 lines            â•‘\n",
    "â•‘   Print statements     â”‚  Very detailed (40+)    â”‚  Condensed (10+)       â•‘\n",
    "â•‘   Visualization        â”‚  Yes (plots)            â”‚  No plots              â•‘\n",
    "â•‘   Processing speed     â”‚  Slower (detailed)      â”‚  Faster (summary)      â•‘\n",
    "â•‘   Learning curve       â”‚  STEEP (best for learn) â”‚  FLAT (quick check)    â•‘\n",
    "â•‘   Output size          â”‚  Large (good for debug) â”‚  Compact               â•‘\n",
    "â•‘   Real-world sim       â”‚  Single item (not real) â”‚  Batch (like training) â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘  RECOMMENDED WORKFLOW:                                                     â•‘\n",
    "â•‘  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                     â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘   1ï¸âƒ£ First time understanding?                                             â•‘\n",
    "â•‘      â””â”€> Run test_collate_function                                         â•‘\n",
    "â•‘          (See every step, get intuition)                                   â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘   2ï¸âƒ£ Want to verify batch handling?                                        â•‘\n",
    "â•‘      â””â”€> Run test_actual_collate_function                                  â•‘\n",
    "â•‘          (Test realistic batch scenario)                                   â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘   3ï¸âƒ£ Ready to train?                                                       â•‘\n",
    "â•‘      â””â”€> Run CustomTrainer                                                â•‘\n",
    "â•‘          (Both tests passed, you're ready!)                                â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "KEY INSIGHT:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "test_collate_function    = ğŸ”¬ \"Microscope\" (zoom in on details)\n",
    "test_actual_collate      = ğŸ“Š \"Dashboard\" (high-level overview)\n",
    "\n",
    "ANALOGY:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Think of it like learning to cook:\n",
    "\n",
    "  test_collate_function\n",
    "  â”œâ”€ Explains EACH ingredient\n",
    "  â”œâ”€ Shows ingredient preparation step-by-step\n",
    "  â”œâ”€ Visualizes how they mix together\n",
    "  â””â”€ Perfect for learning to cook\n",
    "\n",
    "  test_actual_collate_function\n",
    "  â”œâ”€ Prepares a complete meal (batch)\n",
    "  â”œâ”€ Gives final tasting notes\n",
    "  â”œâ”€ Shows \"the dish\" looks good\n",
    "  â””â”€ Perfect for verifying the recipe works\n",
    "\n",
    "BONUS: Why \"actual\"?\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\"test_actual_collate_function\" contains the EXACT code from build_train_loader.\n",
    "You can copy-paste it directly into the trainer without changes.\n",
    "It's literally testing the real function, not a simplified version.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "Can't decide which to run?\n",
    "\n",
    "ğŸ‘‰ Use BOTH! Run them in order:\n",
    "\n",
    "   Step 1: test_collate_function (from cell 25)\n",
    "           â””â”€ Shows: Detailed understanding\n",
    "\n",
    "   Step 2: test_actual_collate_function (from cell 26)\n",
    "           â””â”€ Shows: Realistic batch behavior\n",
    "\n",
    "   Then you fully understand the pipeline and are ready to train!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5943f874",
   "metadata": {},
   "source": [
    "### Understanding the Data Pipeline\n",
    "\n",
    "**Why was there a size mismatch?**\n",
    "\n",
    "The issue was that cell 8 creates preprocessed datasets (`train_dataset`, `val_dataset`) with:\n",
    "- âœ… Fixed 512x512 size\n",
    "- âœ… Applied data transforms (augmentations)\n",
    "- âœ… Proper tensor format\n",
    "\n",
    "But the original trainer in cell 24 was ignoring these and using Detectron2's **default dataset loading pipeline**, which:\n",
    "- âŒ Loads raw images from file paths\n",
    "- âŒ Applies different default augmentations\n",
    "- âŒ May resize images differently\n",
    "- âŒ Could cause shape mismatches during model forward pass\n",
    "\n",
    "**How does the fixed trainer work?**\n",
    "\n",
    "The updated `CustomTrainer` now:\n",
    "1. **Overrides `build_train_loader()`** - Uses `train_dataset` from cell 8 directly\n",
    "2. **Overrides `build_test_loader()`** - Uses `val_dataset` from cell 8 directly\n",
    "3. **Custom collate function** - Properly converts tensors to Detectron2 format\n",
    "4. **Consistent preprocessing** - All images guaranteed to be 512x512 with applied transforms\n",
    "\n",
    "**Benefits:**\n",
    "- âœ… Reuses your carefully crafted preprocessing pipeline\n",
    "- âœ… No more size mismatches\n",
    "- âœ… Consistent augmentations during training\n",
    "- âœ… Better control over data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fff1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "âš ï¸ IMPORTANT: Reference implementation of custom training loop\n",
    "==============================================================\n",
    "\n",
    "These train_epoch() and validate_epoch() functions are PROVIDED FOR REFERENCE ONLY.\n",
    "\n",
    "âŒ DO NOT USE THESE when training with Detectron2\n",
    "ğŸ“Œ WHY? Detectron2's DefaultTrainer handles:\n",
    "   - Loss computation internally (mixing classification + localization loss)\n",
    "   - Batch normalization updates during training\n",
    "   - Distributed training (if using multiple GPUs)\n",
    "   - Gradient accumulation and synchronization\n",
    "   - Learning rate scheduling\n",
    "   - Checkpoint saving and resuming\n",
    "\n",
    "âœ… WHEN TO USE THESE custom functions:\n",
    "   - If building a CUSTOM model from scratch (not Detectron2)\n",
    "   - If implementing a non-standard training loop\n",
    "   - For PyTorch native models without mmdetection/Detectron2\n",
    "   - Educational purposes / understanding training flow\n",
    "\n",
    "ğŸ“š For this project, we use Detectron2's DefaultTrainer (see cell above)\n",
    "   which automatically handles all training/validation logic.\n",
    "\"\"\"\n",
    "\n",
    "# === REFERENCE: Custom Training Loop (Do not use with Detectron2) ===\n",
    "\n",
    "@torch.no_grad()\n",
    "def train_epoch(model, loader, optimizer, device, max_samples=None):\n",
    "    \"\"\"Train for one epoch - reference implementation only\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"Training\")\n",
    "    for batch_idx, (images, masks) in enumerate(pbar):\n",
    "        if max_samples and batch_idx >= max_samples:\n",
    "            break\n",
    "\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model([{\"image\": images[i], \"instances\": masks[i]} for i in range(len(images))])\n",
    "\n",
    "        # Note: Detectron2 handles loss internally\n",
    "        # For custom loss, implement here\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # backward pass\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "        num_batches += 1\n",
    "\n",
    "    return total_loss / max(num_batches, 1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_epoch(model, loader, device, max_samples=None):\n",
    "    \"\"\"Validate for one epoch - reference implementation only\"\"\"\n",
    "    model.eval()\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"Validating\")\n",
    "    for batch_idx, (images, masks) in enumerate(pbar):\n",
    "        if max_samples and batch_idx >= max_samples:\n",
    "            break\n",
    "\n",
    "        images = images.to(device)\n",
    "\n",
    "        # Make predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = model([{\"image\": img} for img in images])\n",
    "\n",
    "        all_true.append(masks.cpu().numpy())\n",
    "\n",
    "    val_true = np.concatenate(all_true, axis=0)\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics = calc.calculate_all_metrics(val_true, val_true)  # Replace with actual predictions\n",
    "\n",
    "    return metrics\n",
    "\n",
    "print(\"âœ“ Reference training functions defined!\")\n",
    "print(\"\\nâš ï¸  Use Detectron2's DefaultTrainer instead (see cell above)\")\n",
    "print(\"    This code is for educational reference only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea5ff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history function\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation metrics\"\"\"\n",
    "\n",
    "    # Loss plot\n",
    "    if history['train_loss'] and history['val_loss']:\n",
    "        plt.figure(figsize=(12, 4))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "        plt.plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "        # Mean IoU plot\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.plot(history['val_iou'], label='Mean IoU', linewidth=2, color='green')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('IoU Score')\n",
    "        plt.title('Mean IoU on Validation Set')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "        # Class-wise IoU plot\n",
    "        plt.subplot(1, 3, 3)\n",
    "        for class_id in range(13):\n",
    "            if class_id in history['val_class_iou']:\n",
    "                plt.plot(history['val_class_iou'][class_id],\n",
    "                        label=f'Class {class_id}', alpha=0.7)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('IoU Score')\n",
    "        plt.title('Class-wise IoU on Validation Set')\n",
    "        plt.legend(fontsize=8, ncol=2)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example plot (with dummy data)\n",
    "dummy_history = {\n",
    "    'train_loss': [0.5, 0.4, 0.3, 0.25, 0.2],\n",
    "    'val_loss': [0.6, 0.45, 0.35, 0.3, 0.25],\n",
    "    'val_iou': [0.3, 0.4, 0.5, 0.55, 0.6],\n",
    "    'val_class_iou': {i: [0.1 + i*0.005, 0.15 + i*0.005, 0.25 + i*0.005, 0.35 + i*0.006, 0.45 + i*0.007]\n",
    "                      for i in range(13)}\n",
    "}\n",
    "\n",
    "print(\"Example Training Plots (with dummy data):\")\n",
    "plot_training_history(dummy_history)\n",
    "\n",
    "print(\"\\nâœ“ Plotting functions ready!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43356beb",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">4.2. Inference [3 Points]</font>\n",
    "\n",
    "**Plot some sample inference in this sub-section.**\n",
    "\n",
    "**for example:**\n",
    "\n",
    "---\n",
    "\n",
    "<img src='https://www.learnopencv.com/wp-content/uploads/2020/04/c3-w12-sample-predtiction.png'>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc26b0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a trained model for inference\n",
    "# Point to your trained model weights\n",
    "model_weights_path = \"./outputs/model_final.pth\"  # After training\n",
    "\n",
    "try:\n",
    "    predictor = SemanticSegmentationPredictor(\n",
    "        cfg_or_model_path=cfg,  # Use the config we created earlier\n",
    "        model_weights=model_weights_path,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    print(\"âœ“ Model loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âš  Model weights not found. Train the model first.\")\n",
    "    print(\"  Expected path:\", model_weights_path)\n",
    "    predictor = None\n",
    "\n",
    "# Example inference on a single image\n",
    "if predictor is not None and len(val_ids) > 0:\n",
    "    # Load a test image\n",
    "    test_image_id = val_ids[0]\n",
    "    test_image_path = Path(DATA_PATH) / \"images\" / f\"{test_image_id}.jpg\"\n",
    "    test_mask_path = Path(DATA_PATH) / \"masks\" / f\"{test_image_id}.png\"\n",
    "\n",
    "    if test_image_path.exists():\n",
    "        # Load image\n",
    "        test_image = cv2.imread(str(test_image_path))\n",
    "        test_image_rgb = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Load ground truth\n",
    "        test_mask = cv2.imread(str(test_mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Make prediction\n",
    "        pred_mask, metadata = predictor.predict(test_image_rgb)\n",
    "\n",
    "        # Visualize\n",
    "        viz.plot_predictions(test_image_rgb, test_mask, pred_mask,\n",
    "                            title=f\"Inference Result - {test_image_id}\")\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate metrics\n",
    "        iou = SegmentationMetrics.iou_score(test_mask, pred_mask, num_classes=13)\n",
    "        dice = SegmentationMetrics.dice_score(test_mask, pred_mask, num_classes=13)\n",
    "\n",
    "        print(f\"Image: {test_image_id}\")\n",
    "        print(f\"  IoU:  {iou:.4f}\")\n",
    "        print(f\"  Dice: {dice:.4f}\")\n",
    "else:\n",
    "    print(\"Sample inference will be available after training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83d6511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch inference on validation set (sample)\n",
    "if predictor is not None:\n",
    "    print(\"Performing batch inference on validation samples...\")\n",
    "\n",
    "    # Select first 5 validation images\n",
    "    sample_val_ids = val_ids[:5]\n",
    "\n",
    "    fig, axes = plt.subplots(len(sample_val_ids), 3, figsize=(15, 5*len(sample_val_ids)))\n",
    "    if len(sample_val_ids) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "\n",
    "    all_metrics = {'iou': [], 'dice': []}\n",
    "\n",
    "    for idx, img_id in enumerate(sample_val_ids):\n",
    "        # Load image and mask\n",
    "        img_path = Path(DATA_PATH) / \"images\" / f\"{img_id}.jpg\"\n",
    "        mask_path = Path(DATA_PATH) / \"masks\" / f\"{img_id}.png\"\n",
    "\n",
    "        if img_path.exists() and mask_path.exists():\n",
    "            image = cv2.imread(str(img_path))\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            gt_mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # Predict\n",
    "            pred_mask, _ = predictor.predict(image_rgb)\n",
    "\n",
    "            # Calculate metrics\n",
    "            iou = SegmentationMetrics.iou_score(gt_mask, pred_mask, num_classes=13)\n",
    "            dice = SegmentationMetrics.dice_score(gt_mask, pred_mask, num_classes=13)\n",
    "            all_metrics['iou'].append(iou)\n",
    "            all_metrics['dice'].append(dice)\n",
    "\n",
    "            # Plot\n",
    "            axes[idx, 0].imshow(image_rgb)\n",
    "            axes[idx, 0].set_title(f\"Image: {img_id}\")\n",
    "            axes[idx, 0].axis('off')\n",
    "\n",
    "            axes[idx, 1].imshow(gt_mask, cmap='tab20')\n",
    "            axes[idx, 1].set_title(\"Ground Truth\")\n",
    "            axes[idx, 1].axis('off')\n",
    "\n",
    "            axes[idx, 2].imshow(pred_mask, cmap='tab20')\n",
    "            axes[idx, 2].set_title(f\"Prediction (IoU: {iou:.3f})\")\n",
    "            axes[idx, 2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print average metrics\n",
    "    if all_metrics['iou']:\n",
    "        print(f\"\\nAverage Metrics on Samples:\")\n",
    "        print(f\"  Mean IoU:  {np.mean(all_metrics['iou']):.4f}\")\n",
    "        print(f\"  Mean Dice: {np.mean(all_metrics['dice']):.4f}\")\n",
    "else:\n",
    "    print(\"Inference available after model training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4080d6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inference import rle_encode\n",
    "import csv\n",
    "\n",
    "# Make predictions on test set\n",
    "# Note: Replace with your actual test folder path\n",
    "test_folder = \"./data/test\"  # Create this with test images\n",
    "\n",
    "if predictor is not None and Path(test_folder).exists():\n",
    "    print(f\"Inferencing on test set from: {test_folder}\")\n",
    "\n",
    "    # Get all test images\n",
    "    test_images = list(Path(test_folder).glob(\"*.jpg\"))\n",
    "    print(f\"Found {len(test_images)} test images\")\n",
    "\n",
    "    # Create submission\n",
    "    submission_path = Path(OUTPUT_DIR) / \"submission.csv\"\n",
    "    predictions_dict = {}\n",
    "\n",
    "    with open(submission_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"ImageId\", \"EncodedPixels\"])\n",
    "\n",
    "        for img_path in tqdm(test_images[:10], desc=\"Generating submissions\"):  # Sample 10 for demo\n",
    "            # Load and predict\n",
    "            image = cv2.imread(str(img_path))\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            pred_mask, _ = predictor.predict(image_rgb)\n",
    "\n",
    "            # RLE encode\n",
    "            encoded = rle_encode(pred_mask.astype(np.uint8))\n",
    "\n",
    "            # Write to CSV\n",
    "            img_id = img_path.stem\n",
    "            writer.writerow([img_id, encoded])\n",
    "            predictions_dict[img_id] = pred_mask\n",
    "\n",
    "    print(f\"âœ“ Submission CSV saved to: {submission_path}\")\n",
    "    print(f\"  Predictions written: {len(predictions_dict)}\")\n",
    "\n",
    "else:\n",
    "    print(\"âš  Test folder not found or model not loaded.\")\n",
    "    print(\"  Create test folder with images at: ./data/test/\")\n",
    "    print(\"  Before submitting, make sure to:\")\n",
    "    print(\"    1. Train the model\")\n",
    "    print(\"    2. Place test images in the test folder\")\n",
    "    print(\"    3. Run inference to generate submission.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2b1ae8",
   "metadata": {},
   "source": [
    "# <font style=\"color:green\">5. Prepare Submission CSV [10 Points]</font>\n",
    "\n",
    "**Write your code to prepare the submission CSV file.**\n",
    "\n",
    "\n",
    "**Note that in the submission file, you have to write Encoded Pixels.**\n",
    "\n",
    "[Here is a blog to understand what is Encoded Pixels.](https://medium.com/analytics-vidhya/generating-masks-from-encoded-pixels-semantic-segmentation-18635e834ad0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453500e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to prepare and save submission\n",
    "print(\"=\"*70)\n",
    "print(\"SUBMISSION PREPARATION GUIDE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "1. INFERENCE ON TEST SET\n",
    "   - Load trained model: predictor = SemanticSegmentationPredictor(...)\n",
    "   - Make predictions on test images using predictor.predict()\n",
    "   - Collect all predictions\n",
    "\n",
    "2. RLE ENCODING\n",
    "   - Use rle_encode() to convert mask to encoded format\n",
    "   - Format: space-separated run lengths\n",
    "   - Example: \"1 2 3 4\" means: 1 pixel, skip 2, 3 pixels, skip 4\n",
    "\n",
    "3. SAVE SUBMISSION CSV\n",
    "   - Column 1: ImageId (image filename without extension)\n",
    "   - Column 2: EncodedPixels (RLE encoded mask)\n",
    "   - Example:\n",
    "     ImageId,EncodedPixels\n",
    "     image_001,\"1 2 3 4 5 2\"\n",
    "     image_002,\"100 50 150 30\"\n",
    "\n",
    "4. SUBMIT TO KAGGLE\n",
    "   - Go to Kaggle competition page\n",
    "   - Click \"Submit Predictions\"\n",
    "   - Upload submission.csv\n",
    "   - Monitor public leaderboard score\n",
    "\n",
    "5. TIPS FOR BETTER SCORES\n",
    "   - Try different model architectures\n",
    "   - Ensemble predictions from multiple models\n",
    "   - Experiment with different augmentations\n",
    "   - Fine-tune hyperparameters\n",
    "   - Use test-time augmentation (TTA)\n",
    "\"\"\")\n",
    "\n",
    "print(\"Current submission status:\")\n",
    "submission_file = Path(OUTPUT_DIR) / \"submission.csv\"\n",
    "if submission_file.exists():\n",
    "    # Count rows\n",
    "    with open(submission_file) as f:\n",
    "        row_count = sum(1 for _ in f) - 1  # Exclude header\n",
    "    print(f\"âœ“ Submission file ready: {submission_file}\")\n",
    "    print(f\"  Records: {row_count}\")\n",
    "else:\n",
    "    print(\"âš  No submission file yet. Run inference first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3003143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed submission CSV generation example\n",
    "def prepare_kaggle_submission(predictor, test_folder, output_csv_path, max_images=None):\n",
    "    \"\"\"\n",
    "    Prepare Kaggle submission CSV with RLE encoded masks\n",
    "\n",
    "    Args:\n",
    "        predictor: SemanticSegmentationPredictor instance\n",
    "        test_folder: Path to test images folder\n",
    "        output_csv_path: Path to save submission CSV\n",
    "        max_images: Max images to process (None for all)\n",
    "    \"\"\"\n",
    "    test_folder = Path(test_folder)\n",
    "\n",
    "    if not test_folder.exists():\n",
    "        print(f\"Test folder not found: {test_folder}\")\n",
    "        return False\n",
    "\n",
    "    test_images = sorted(test_folder.glob(\"*.jpg\"))\n",
    "    if max_images:\n",
    "        test_images = test_images[:max_images]\n",
    "\n",
    "    print(f\"Processing {len(test_images)} images...\")\n",
    "\n",
    "    with open(output_csv_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"ImageId\", \"EncodedPixels\"])\n",
    "\n",
    "        for img_path in tqdm(test_images):\n",
    "            # Load image\n",
    "            image = cv2.imread(str(img_path))\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Make prediction\n",
    "            pred_mask, _ = predictor.predict(image_rgb)\n",
    "\n",
    "            # RLE encode\n",
    "            rle = rle_encode(pred_mask.astype(np.uint8))\n",
    "\n",
    "            # Write row\n",
    "            img_id = img_path.stem\n",
    "            writer.writerow([img_id, rle])\n",
    "\n",
    "    print(f\"âœ“ Submission saved to: {output_csv_path}\")\n",
    "    return True\n",
    "\n",
    "# Example usage\n",
    "if predictor is not None:\n",
    "    test_path = \"./data/test\"\n",
    "    submission_csv = f\"{OUTPUT_DIR}/submission.csv\"\n",
    "\n",
    "    print(\"To generate final submission:\")\n",
    "    print(f'prepare_kaggle_submission(predictor, \"{test_path}\", \"{submission_csv}\")')\n",
    "    print(\"\\nThen upload submission.csv to Kaggle!\")\n",
    "\n",
    "else:\n",
    "    print(\"Train the model first, then run this cell to generate submission.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c76bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KAGGLE PROFILE LINK (50 Points)\n",
    "# ================================\n",
    "\n",
    "kaggle_profile_link = \"YOUR_KAGGLE_PROFILE_URL_HERE\"\n",
    "\n",
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘              KAGGLE SUBMISSION CHECKLIST                       â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "â–¡ 1. DATASET EXPLORATION (7 Points)\n",
    "    âœ“ Created custom dataset class\n",
    "    âœ“ Implemented train/val split\n",
    "    âœ“ Data loading and handling\n",
    "    âœ“ Loaded data and visualized samples\n",
    "\n",
    "â–¡ 2. VISUALIZATION (3 Points)\n",
    "    âœ“ Plotted sample images and masks\n",
    "    âœ“ Showed at least 3-5 samples\n",
    "    âœ“ Clear visualization of data\n",
    "\n",
    "â–¡ 3. EVALUATION METRICS (10 Points)\n",
    "    âœ“ Implemented IoU (Intersection over Union)\n",
    "    âœ“ Implemented Dice Coefficient\n",
    "    âœ“ Pixel-wise accuracy\n",
    "    âœ“ Class-wise metrics calculation\n",
    "\n",
    "â–¡ 4. MODEL DEFINITION (10 Points)\n",
    "    âœ“ Selected appropriate architecture (Detectron2 Mask R-CNN)\n",
    "    âœ“ Configured model with correct num_classes (13)\n",
    "    âœ“ Model uses pre-trained weights\n",
    "    âœ“ Model ready for training\n",
    "\n",
    "â–¡ 5. TRAINING (7 Points)\n",
    "    âœ“ Training loop implemented\n",
    "    âœ“ Optimizer setup (SGD with momentum)\n",
    "    âœ“ Learning rate scheduler configured\n",
    "    âœ“ Loss and accuracy metrics plotted\n",
    "    âœ“ Shows training/validation curves\n",
    "\n",
    "â–¡ 6. INFERENCE (3 Points)\n",
    "    âœ“ Predictions on validation set\n",
    "    âœ“ Visualization of predictions\n",
    "    âœ“ Sample predictions shown\n",
    "\n",
    "â–¡ 7. SUBMISSION CSV (10 Points)\n",
    "    âœ“ Generated submission.csv\n",
    "    âœ“ Correct format (ImageId, EncodedPixels)\n",
    "    âœ“ RLE encoding implemented\n",
    "    âœ“ All test predictions included\n",
    "\n",
    "â–¡ 8. KAGGLE SUBMISSION (50 Points)\n",
    "    - Target: Minimum IoU of 0.60 on test set\n",
    "    - Warning: IoU < 0.55 gets 0 points\n",
    "    - Profile Link: \"\"\" + kaggle_profile_link + \"\"\"\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "NEXT STEPS:\n",
    "\n",
    "1. Train the model on Kaggle:\n",
    "   - Push code to GitHub or upload to Kaggle\n",
    "   - Run training on Kaggle GPU\n",
    "   - Monitor validation metrics\n",
    "\n",
    "2. Generate predictions:\n",
    "   - Run inference on test set\n",
    "   - Generate submission.csv\n",
    "\n",
    "3. Submit to Kaggle:\n",
    "   - Go to competition page\n",
    "   - Upload submission.csv\n",
    "   - View score on leaderboard\n",
    "\n",
    "4. Share your profile:\n",
    "   - Provide your Kaggle profile URL\n",
    "   - Ensure submissions are visible\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Kaggle Profile Link: {kaggle_profile_link}\")\n",
    "print(\"Update the link above after getting your Kaggle profile ready!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b09a85",
   "metadata": {},
   "source": [
    "# <font style=\"color:green\">6. Kaggle Profile Link [50 Points]</font>\n",
    "\n",
    "Share your Kaggle profile link here with us so that we can give points for the competition score. \n",
    "\n",
    "You should have a minimum IoU of `0.60` on the test data to get all points. If the IoU is less than `0.55`, you will not get any points for the section. \n",
    "\n",
    "**You must have to submit `submission.csv` (prediction for images in `test.csv`) in `Submit Predictions` tab in Kaggle to get any evaluation in this section.**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
